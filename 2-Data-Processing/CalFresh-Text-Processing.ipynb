{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Text Processing Pipeline for Cal-Fresh Application Dataset\n",
    "\n",
    "Author: Rocio Ng (DSWG Lead)\n",
    "\n",
    "### Summary:  \n",
    "* The purpose of this notebook is to prototype and test methods for processing free text entered into Applications for the CalFresh Program (https://www.getcalfresh.org/)\n",
    "* Notebook applies helper modules that do the following:\n",
    "    1. Apply light processing to text\n",
    "    2. Attempt to correct mispelled words in the text\n",
    "    3. Apply white-list to redact text that may contain personal information\n",
    "\n",
    "### Resources:\n",
    "* Peter Norvig's Spell Corrector Tutorial (http://norvig.com/spell-correct.html)\n",
    "* Spanish Language Corpus - https://www.corpusdata.org/spanish.asp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once') # displays warnings only once\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# For loading Helper Functions\n",
    "module_path = os.path.abspath(os.path.join('2-Helper-Modules'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# For Multicore processing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Helper Modules\n",
    "from spell_checking_functions_v3 import *\n",
    "from text_processing_functions import *\n",
    "from whitelist_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing spell checker\n",
    "en_spellchecker.correction_phrase(\"helpp meh with calfrsh, whil i'm applying for ssi  .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detect('Hi')) # False Negative Results\n",
    "# print(detect('I currently live in my truck'))\n",
    "# print(detect(\"estoy embarazada\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "* Make sure paths point to where data files are stored locally if you choose to rename/move things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"../../1-Data/500_sample_results.csv\")\n",
    "# text_df = pd.read_csv(\"1-Data-Files/orig_entRep_300.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df.dropna(subset=['with_entity_replacement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "* Light text processing\n",
    "* Count Spelling Errors\n",
    "* Detect Langage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo \n",
    "Spellchecker.initial_text_processing(\" PERSON, I'm wenT to The Store at (CARDINAL)!!\")\n",
    "Spellchecker.initial_text_processing(\"Por ahora no estoy trabajando necesito de NAME ayuda el mes anterior si recibir \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['processed_phrase'] = text_df.with_entity_replacement\\\n",
    "    .apply(lambda x: Spellchecker.initial_text_processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['spelling_errors'] = text_df.processed_phrase\n",
    "text_df = text_df.sort_values('spelling_errors', ascending = False)\n",
    "text_df['language'] = text_df.processed_phrase.apply(lambda x: detect_B(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.groupby(by = \"language\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_df[text_df.language.isin(['None'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = text_df[~text_df.language.isin(['None'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Spell Checking Functions\n",
    "\n",
    "* Convert Dataframe column of Phrases to List of Tuples (Word, Language) to enable Multiprocessing\n",
    "* Run spell Correction_phrase function on text\n",
    "* Append back to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_error_list = list(zip(text_df['processed_phrase'], text_df['language']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview\n",
    "spelling_error_list[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pool = Pool(processes=4) # change to number of cores in machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing edge cases\n",
    "spell_correction_language((\"semesters\", \"en\")) # would correct to a different word even though correct\n",
    "spell_correction_language((\"alot\", \"en\"))\n",
    "spell_correction_language((\"paralized\", \"en\"))  # corrects to 'penalized' instead of paralyzed \n",
    "# spell_correction_language((\"farmacie\", \"es\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply spell correction by language across all text\n",
    "%time spelling_corrections = my_pool.map(spell_correction_language, spelling_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_corrections[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append results to dataframe\n",
    "text_df['spelling_corrections'] = spelling_corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_df = text_df.iloc[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv(\"gcf_circumstances_spell_correct.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply White List to Spell Corrected Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase = \"This is a Test.   For Rocio. Hello. \"\n",
    "check_whitelist(test_phrase, whitelist_list, \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['whitelisted_phrase'] = text_df.spelling_corrections\\\n",
    "    .apply(lambda x: check_whitelist(x, whitelist_list, \"replace\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv(\"gcf_circumstances_spell_correct_whitelist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Effectiveness of Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_df['words_removed_raw_words'] = text_df.original_additional_information_text\\\n",
    "#     .apply(lambda x: int(check_whitelist(x, whitelist_list)[1]))\n",
    "\n",
    "# text_df['words_removed_spell_corrected'] = text_df.spelling_corrections\\\n",
    "#     .apply(lambda x: int(check_whitelist(x, whitelist_list, \"remove\")[1]))\n",
    "\n",
    "# text_df = text_df\\\n",
    "#     .assign(pct_improvement = 100*(1 - (text_df.words_removed_spell_corrected/text_df.words_removed_raw_words)))\\\n",
    "#     .assign(improvement = text_df.words_removed_raw_words - text_df.words_removed_spell_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_words = [\"test\", \"in\", \"an\", \"never\", \"work\", \"part\", \"house\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
